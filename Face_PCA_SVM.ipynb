{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recogognition using PCA + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO ADD PIPELINE TO ADJUST PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import os,sys\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/ldarmet/Face recognition/CroppedYale'\n",
    "def read_images(path, sz=(168,192)): \n",
    "    t0 = time()\n",
    "    c=0\n",
    "    \n",
    "    y = []\n",
    "    X = np.empty([1, 32256]) #Image are resized to 168x192\n",
    "    for dirname , dirnames , filenames in os.walk(path):\n",
    "        for subdirname in dirnames:\n",
    "            subject_path = os.path.join(dirname , subdirname) \n",
    "            for filename in os.listdir(subject_path):\n",
    "                try:\n",
    "                    print 'Label',c+1,'on :', 37\n",
    "                    im = Image.open(os.path.join(subject_path , filename)) \n",
    "                    im = im.convert(\"L\")\n",
    "                    # resize to given size (if given)\n",
    "                    if (sz is not None):\n",
    "                        im = im.resize(sz, Image.ANTIALIAS)\n",
    "                    X = np.vstack((X,np.asarray(im, dtype=np.uint8).ravel()))\n",
    "                    #X.append(np.asarray(im, dtype=np.uint8).ravel())    \n",
    "                    y.append(c)\n",
    "                except IOError:\n",
    "                    print \"I/O error({0}): {1}\".format(\"errno\", \"strerror\") #there is some text files in the path\n",
    "                except:\n",
    "                    print \"Unexpected error:\", sys.exc_info()[0] \n",
    "                    raise\n",
    "            c = c+1\n",
    "        \n",
    "    y = np.asarray(y)\n",
    "    X = X[1::,:] # Skip the first line which is void\n",
    "    print(\"Image read in %0.3fs\" % (time() - t0))\n",
    "    return [X,y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EigenFaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eigenfaces(X_train,X_test,n_components=120):\n",
    "    \n",
    "    # Display progress logs on stdout\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "\n",
    "\n",
    "    print(\"Extracting the top %d eigenfaces from %d faces\"\n",
    "      % (n_components, X_train.shape[0]))\n",
    "    t0 = time()\n",
    "    pca = PCA(n_components=n_components, svd_solver='randomized',\n",
    "      whiten=True).fit(X_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    \n",
    "    #eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "    \n",
    "    print(\"Projecting the input data on the eigenfaces orthonormal basis\")\n",
    "    t0 = time()\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    print(\"EigenFaces done in %0.3fs\" % (time() - t0))\n",
    "    \n",
    "    \n",
    "    return X_train_pca, X_test_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label  0 on :  64\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "I/O error(errno): strerror\n",
      "Image read in 140.283s\n",
      "CPU times: user 1min 34s, sys: 45.3 s, total: 2min 19s\n",
      "Wall time: 2min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X,y = read_images(path=path)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the top 120 eigenfaces from 1654 faces\n",
      "done in 8.068s\n",
      "Projecting the input data on the eigenfaces orthonormal basis\n",
      "EigenFaces done in 0.668s\n",
      "CPU times: user 20.7 s, sys: 7.52 s, total: 28.2 s\n",
      "Wall time: 8.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_pca, X_test_pca = eigenfaces(X_train,X_test,n_components=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "Best estimator found by grid search:\n",
      "SVC(C=1000.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "CPU times: user 1min 7s, sys: 880 ms, total: 1min 8s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "\n",
    "param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'),cv=3, param_grid)\n",
    "clf = clf.fit(X_train_pca, y_train)\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative evaluation of the model quality on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Predicting people's names on the test set\")\n",
    "t0 = time()\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline and CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include number of component in PCA to gridsearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator found by grid search:\n",
      "Pipeline(steps=[('reduce_dim', PCA(copy=True, iterated_power='auto', n_components=200, random_state=None,\n",
      "  svd_solver='randomized', tol=0.0, whiten=True)), ('classify', SVC(C=1000.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.0001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "0.880894800484\n",
      "CPU times: user 2min 53s, sys: 3.48 s, total: 2min 56s\n",
      "Wall time: 20min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = Pipeline([\n",
    "    ('reduce_dim', PCA(svd_solver='randomized',\n",
    "      whiten=True)),\n",
    "    ('classify', SVC(kernel='rbf', class_weight='balanced'))\n",
    "])\n",
    "\n",
    "N_FEATURES_OPTIONS = range(150,250,50)\n",
    "C_OPTIONS = [1e3, 5e3, 1e4, 5e4, 1e5]\n",
    "gamma_OPTIONS = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]\n",
    "        \n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'classify__C': C_OPTIONS,\n",
    "        'classify__gamma' : gamma_OPTIONS\n",
    "    }]\n",
    "\n",
    "grid = GridSearchCV(pipe, cv=3, n_jobs= -1,param_grid=param_grid)\n",
    "grid = grid.fit(X_train, y_train)\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(grid.best_estimator_)\n",
    "print grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative evaluation of the model quality on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting people's names on the test set\n",
      "done in 0.711s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.87      0.84        15\n",
      "          1       0.96      0.96      0.96        23\n",
      "          2       0.95      0.90      0.93        21\n",
      "          3       1.00      1.00      1.00        27\n",
      "          4       0.93      0.86      0.89        29\n",
      "          5       0.95      0.90      0.93        21\n",
      "          6       0.96      0.92      0.94        24\n",
      "          7       0.88      0.84      0.86        25\n",
      "          8       0.96      0.92      0.94        24\n",
      "          9       1.00      0.92      0.96        25\n",
      "         10       0.76      0.94      0.84        17\n",
      "         11       0.93      0.93      0.93        15\n",
      "         12       0.94      1.00      0.97        29\n",
      "         13       0.86      0.95      0.90        19\n",
      "         14       1.00      0.95      0.97        19\n",
      "         15       0.86      0.90      0.88        21\n",
      "         16       1.00      0.83      0.91        24\n",
      "         17       0.41      0.88      0.56        17\n",
      "         18       1.00      0.76      0.86        21\n",
      "         19       0.83      0.80      0.82        25\n",
      "         20       1.00      0.86      0.93        22\n",
      "         21       0.95      0.83      0.89        24\n",
      "         22       0.94      0.79      0.86        19\n",
      "         23       1.00      0.96      0.98        27\n",
      "         24       0.87      0.91      0.89        22\n",
      "         25       0.94      1.00      0.97        16\n",
      "         26       1.00      0.95      0.97        19\n",
      "         27       0.95      0.95      0.95        19\n",
      "         28       0.95      0.95      0.95        22\n",
      "         29       0.96      1.00      0.98        26\n",
      "         30       1.00      0.86      0.92        21\n",
      "         31       0.90      1.00      0.95        19\n",
      "         32       0.89      0.80      0.84        20\n",
      "         33       0.94      0.94      0.94        18\n",
      "         34       0.87      0.95      0.91        21\n",
      "         35       1.00      1.00      1.00        18\n",
      "         36       1.00      1.00      1.00        19\n",
      "         37       0.95      0.91      0.93        23\n",
      "\n",
      "avg / total       0.93      0.91      0.92       816\n",
      "\n",
      "[[13  0  0 ...,  0  0  0]\n",
      " [ 0 22  0 ...,  0  0  0]\n",
      " [ 1  0 19 ...,  0  0  0]\n",
      " ..., \n",
      " [ 0  0  0 ..., 18  0  0]\n",
      " [ 0  0  0 ...,  0 19  0]\n",
      " [ 0  0  0 ...,  0  0 21]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting people's names on the test set\")\n",
    "t0 = time()\n",
    "y_pred = grid.predict(X_test)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative evaluation of the predictions using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-062c13ed1ac0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m prediction_titles = [title(y_pred, y_test, target_names, i)\n\u001b[0;32m---> 21\u001b[0;31m                      for i in range(y_pred.shape[0])]\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mplot_gallery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_titles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'target_names' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "\n",
    "# plot the result of the prediction on a portion of the test set\n",
    "\n",
    "def title(y_pred, y_test, target_names, i):\n",
    "    pred_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n",
    "    true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n",
    "    return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)\n",
    "\n",
    "prediction_titles = [title(y_pred, y_test, target_names, i)\n",
    "                     for i in range(y_pred.shape[0])]\n",
    "\n",
    "plot_gallery(X_test, prediction_titles, h, w)\n",
    "\n",
    "# plot the gallery of the most significative eigenfaces\n",
    "\n",
    "eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
    "plot_gallery(eigenfaces, eigenface_titles, h, w)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
